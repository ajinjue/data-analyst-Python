{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3387d581-624b-4521-ac7a-435f715f1740",
   "metadata": {},
   "source": [
    "# Land price web scraping project\n",
    "The data to be scraped is at https://www.jumia.cm/en/land-plots. It contains the location, surface area (squared metre) and the prices per squared metre for various neigborhoods in Litoral region, Cameroon.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446090fd-b238-4ccd-8f06-809804b65b54",
   "metadata": {},
   "source": [
    "## Steps involved\n",
    "- Import libraries\n",
    "- Create ETL functions\n",
    "- Scrape the data\n",
    "- Create CSV file of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6c743-56bc-44cf-98a7-c826c8a65382",
   "metadata": {},
   "source": [
    "### 1.) Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e0ea4b5-3789-461f-a6fa-74e6d0bf77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d61924-c9b3-4d31-b46c-1ce1cb848c6f",
   "metadata": {},
   "source": [
    "### 2.) Create ETL functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "30905124-bee6-4e0a-9793-6c6aa7922956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to append urls\n",
    "urls_list = []\n",
    "\n",
    "# define first function\n",
    "def get_page_urls(page):\n",
    "    \"\"\" Get URLs on the page and concatenate the base URL to each\n",
    "    \n",
    "    Arg:\n",
    "        page (int): the page number\n",
    "        \n",
    "    Returns:\n",
    "        list: list of URLs\n",
    "    \"\"\"\n",
    "    base_url = 'https://www.jumia.cm'\n",
    "    # Access the web page\n",
    "    response = requests.get(f'https://www.jumia.cm/en/land-plots?page={page}')\n",
    "    # Get the text from the web page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Find urls of all articles on the web page and append to url_list\n",
    "    list_urls = soup.find_all('article')\n",
    "    for partial_url in list_urls:\n",
    "        new_url = base_url + partial_url.find('a')['href']\n",
    "        urls_list.append(new_url)\n",
    "    return urls_list\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9b679ea-b0ba-4fff-8a8f-435f2f94784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to append items\n",
    "items_list = []\n",
    "\n",
    "# define the second function\n",
    "def extract_transform(url):\n",
    "    \"\"\" Extract items from the URL and transform or clean them\n",
    "    Arg:\n",
    "        url (str): URL of the web page\n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    # Access the web page\n",
    "    response = requests.get(url)\n",
    "    # Get the text from the web page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extract items\n",
    "    location = soup.find('span',{'itemprop':'addressLocality'}).get_text()\n",
    "    area = float(soup.find_all('h3')[1].get_text().replace('Area', '').replace(' m2', ''))\n",
    "    price = int(soup.find('span', {'itemprop':'price'}).get_text().replace(',', ''))\n",
    "    seller = soup.find_all('dd')[0].get_text()\n",
    "    \n",
    "    # Create a dictionary to store items\n",
    "    items = {\n",
    "        'Location': location,\n",
    "        'Area': area,\n",
    "        'Price': price,\n",
    "        'Seller': seller\n",
    "    }\n",
    "    # Append items to item_list\n",
    "    items_list.append(items)\n",
    "    \n",
    "    return items_list\n",
    "             \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19969c-9f8d-4067-a4a7-ca7634e869c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
