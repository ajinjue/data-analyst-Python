{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3387d581-624b-4521-ac7a-435f715f1740",
   "metadata": {},
   "source": [
    "# Land price web scraping project\n",
    "The data to be scraped is at https://www.jumia.cm/en/land-plots. It contains the location, surface area (squared metre) and the prices per squared metre for various neigborhoods in Litoral region, Cameroon.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446090fd-b238-4ccd-8f06-809804b65b54",
   "metadata": {},
   "source": [
    "## Steps involved\n",
    "- Import libraries\n",
    "- Create ETL functions\n",
    "- Scrape the data\n",
    "- Create CSV file of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6c743-56bc-44cf-98a7-c826c8a65382",
   "metadata": {},
   "source": [
    "### 1.) Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e0ea4b5-3789-461f-a6fa-74e6d0bf77c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d61924-c9b3-4d31-b46c-1ce1cb848c6f",
   "metadata": {},
   "source": [
    "### 2.) Create ETL functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "30905124-bee6-4e0a-9793-6c6aa7922956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to append urls\n",
    "urls_list = []\n",
    "\n",
    "# define first function\n",
    "def get_page_urls(page):\n",
    "    \"\"\" Get URLs on the page and concatenate the base URL to each\n",
    "    \n",
    "    Arg:\n",
    "        page (int): the page number\n",
    "        \n",
    "    Returns:\n",
    "        list: list of URLs\n",
    "    \"\"\"\n",
    "    base_url = 'https://www.jumia.cm'\n",
    "    # Access the web page\n",
    "    response = requests.get(f'https://www.jumia.cm/en/land-plots?page={page}')\n",
    "    # Get the text from the web page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Find urls of all articles on the web page and append to url_list\n",
    "    list_urls = soup.find_all('article')\n",
    "    for partial_url in list_urls:\n",
    "        new_url = base_url + partial_url.find('a')['href']\n",
    "        urls_list.append(new_url)\n",
    "    return urls_list\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a9b679ea-b0ba-4fff-8a8f-435f2f94784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list to append items\n",
    "items_list = []\n",
    "\n",
    "# define the second function\n",
    "def extract_transform(url):\n",
    "    \"\"\" Extract items from the URL and transform or clean them\n",
    "    Arg:\n",
    "        url (str): URL of the web page\n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "    \"\"\"\n",
    "    # Access the web page\n",
    "    response = requests.get(url)\n",
    "    # Get the text from the web page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extract items\n",
    "    location = soup.find('span',{'itemprop':'addressLocality'}).get_text()\n",
    "    area = float(soup.find_all('h3')[1].get_text().replace('Area', '').replace(' m2', ''))\n",
    "    price = int(soup.find('span', {'itemprop':'price'}).get_text().replace(',', ''))\n",
    "    seller = soup.find_all('dd')[0].get_text()\n",
    "    \n",
    "    # Create a dictionary to store items\n",
    "    items = {\n",
    "        'Location': location,\n",
    "        'Area': area,\n",
    "        'Price': price,\n",
    "        'Seller': seller\n",
    "    }\n",
    "    # Append items to item_list\n",
    "    items_list.append(items)\n",
    "    \n",
    "    return items_list\n",
    "             \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ec326b46-8059-4004-b2f5-946547838a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Location': 'Ngaoundéré',\n",
       "  'Area': 500.0,\n",
       "  'Price': 5000000,\n",
       "  'Seller': 'DJUNTU MICHAEL'}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_transform(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "195a5edf-a52d-4c9c-a6b4-20f5d9972408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.jumia.cm/en/terrain-titre-en-or-pid11720026',\n",
       " 'https://www.jumia.cm/en/terrain-tr-s-bien-plac-vendre-a-lendi-quartier-g-n-ral--pid11754625',\n",
       " 'https://www.jumia.cm/en/vente-terrain-titr-de-300m2-logpom-pid11754459',\n",
       " 'https://www.jumia.cm/en/a-vendre-terrain-pid11754165',\n",
       " 'https://www.jumia.cm/en/terrain-vendre--pid11754131',\n",
       " 'https://www.jumia.cm/en/a-vendre-terrain-pid11754083',\n",
       " 'https://www.jumia.cm/en/a-vendre-terrain-pid11754082',\n",
       " 'https://www.jumia.cm/en/a-vendre-terrain-pid11754064',\n",
       " 'https://www.jumia.cm/en/a-vendre-terrain-pid11754031']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_page_urls(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ef880647-6811-4f92-ad84-f843516c43b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = url_list[0]\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9a4ffac8-a601-479d-ae8b-aa838054057a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DJUNTU MICHAEL'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "location = soup.find('span', {'itemprop':'addressLocality'}).get_text()\n",
    "area = float(soup.find_all('h3')[1].get_text().replace('Area', '').replace(' m2', ''))\n",
    "price = int(soup.find('span', {'itemprop':'price'}).get_text().replace(',', ''))\n",
    "seller = soup.find_all('dd')[0].get_text()\n",
    "seller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163228d0-45c4-49f1-be90-77bc41b679c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7f27d1-d27d-4248-a2eb-8c88ab7a8444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
